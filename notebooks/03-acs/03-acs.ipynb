{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports you will need in the whole lab\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB, ComplementNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from skimage.exposure import histogram\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu, laplace\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.util import invert\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "def showHist(img):\n",
    "    # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "    \n",
    "    plt.bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name, newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            data.append([float(element) for element in row[0].split(',')])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data():\n",
    "    test_data = read_data('validating_data.csv')\n",
    "\n",
    "    test_data_true = []\n",
    "    with open('./true_validating_data.csv', newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            test_data_true.append(float(row[0]))\n",
    "            \n",
    "    return test_data, test_data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritic_segmentation(image):\n",
    "    img = np.where(image > 0, 0, 1)\n",
    "    horizontal_projection = np.sum(img, axis = 1)\n",
    "    # got certain line\n",
    "    baseline_location_index = horizontal_projection.argmax()\n",
    "    \n",
    "    diacritic_image = np.copy(image)\n",
    "    previous_val = -1\n",
    "    current_val = diacritic_image[baseline_location_index,:].argmin()\n",
    "    \n",
    "    while previous_val != current_val:\n",
    "        diacritic_image = flood_fill(diacritic_image, (baseline_location_index, current_val), 255)\n",
    "        previous_val = current_val\n",
    "        current_val = diacritic_image[baseline_location_index,:].argmin()\n",
    "\n",
    "    image_text = image - diacritic_image\n",
    "    image_text = np.where(image_text > 0, 0, 1)\n",
    "    \n",
    "    # show_images([image, diacritic_image, image_text])\n",
    "\n",
    "    return diacritic_image.astype(np.uint8), image_text.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(img):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Preprocess an image.\n",
    "        1. Grayscale\n",
    "        2. OTSU Threshold\n",
    "        3. Binarization\n",
    "        4. Checking image binary is 0 or 255\n",
    "        5. Laplacian filter\n",
    "    \n",
    "    RETURN:\n",
    "    binary_image, edge_image, skeleton_image, diacritic_image, text_image\n",
    "    '''\n",
    "    grayscale_image = rgb2gray(img)\n",
    "    if grayscale_image.max() <= 1:\n",
    "        grayscale_image = (grayscale_image * 255)\n",
    "    grayscale_image = grayscale_image.astype(np.uint8)\n",
    "    \n",
    "    global_threshold = threshold_otsu(grayscale_image)\n",
    "    binary_image = np.where(grayscale_image > global_threshold, 255, 0)\n",
    "    # binary_image = grayscale_image > global_threshold\n",
    "    \n",
    "    image_histogram = np.asarray(histogram(binary_image, nbins=256))\n",
    "    if image_histogram.argmax() <= 150:\n",
    "        binary_image = 255 - binary_image\n",
    "    binary_image = binary_image.astype(np.uint8)\n",
    "    \n",
    "    edge_image = cv2.convertScaleAbs(cv2.Laplacian(binary_image, cv2.CV_16S, ksize=3))\n",
    "    edge_image = 255 - edge_image\n",
    "    edge_image[edge_image == 255] = 1\n",
    "    \n",
    "    inverted_image = invert(binary_image)\n",
    "    inverted_image[inverted_image == 255] = 1\n",
    "    skeleton_image = skeletonize(inverted_image, method='zhang')\n",
    "    skeleton_image = invert(skeleton_image)\n",
    "    skeleton_image = skeleton_image.astype(np.uint8)\n",
    "    \n",
    "    diacritic_image, text_image = diacritic_segmentation(binary_image)\n",
    "    diacritic_image = np.where(diacritic_image > 0, 1, 0)\n",
    "    diacritic_image = diacritic_image.astype(np.uint8)\n",
    "    # show_images([binary_image, edge_image, skeleton_image, diacritic_image, text_image], ['BINARY', 'EDGE IMAGE', 'SKELETON', 'DIACRITIC_IMAGE', 'TEXT'])\n",
    "    \n",
    "    return binary_image, edge_image, skeleton_image, diacritic_image, text_image\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# x = preprocessing_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvsl_features(edge_image):\n",
    "    thresh = cv2.threshold(edge_image, 0, 1, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Detect horizontal lines\n",
    "    horizontal_image = np.ones(edge_image.shape)\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40,1))\n",
    "    detect_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    cnts = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    # for c in cnts:\n",
    "    cv2.drawContours(horizontal_image, cnts, -1, (0, 0, 0), 2)\n",
    "        \n",
    "    horizontal_image = np.where(horizontal_image > 0, 0, 1)\n",
    "    horizontal_lines = np.sum(horizontal_image, axis=1)\n",
    "    h_unique, h_count = np.unique(horizontal_lines, return_counts=True)\n",
    "    h_dict = dict(zip(h_unique, h_count))\n",
    "    frequency_horizontal_lines = edge_image.shape[0] - h_dict[0] if h_dict[0] != edge_image.shape[0] else 0\n",
    "    \n",
    "    # Detect vertical lines\n",
    "    vertical_image = np.ones(edge_image.shape)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,10))\n",
    "    detect_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "    cnts = cv2.findContours(detect_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # for c in cnts:\n",
    "    cv2.drawContours(vertical_image, cnts, -1, (0, 0, 0), 2)\n",
    "        \n",
    "    vertical_image = np.where(vertical_image > 0, 0, 1)\n",
    "    vertical_lines = np.sum(vertical_image, axis=0)\n",
    "    v_unique, v_count = np.unique(vertical_lines, return_counts=True)\n",
    "    v_dict = dict(zip(v_unique, v_count))\n",
    "    frequency_vertical_lines = edge_image.shape[1] - v_dict[0] if v_dict[0] != edge_image.shape[1] else 0\n",
    "    \n",
    "    inverted_img = np.where(edge_image > 0, 0, 1)\n",
    "    \n",
    "    # show_images([edge_image, inverted_img])\n",
    "    \n",
    "    sum_frequencies = frequency_horizontal_lines + frequency_vertical_lines\n",
    "    number_pixels = np.sum(np.sum(inverted_img, axis=0))\n",
    "    ratio = (number_pixels - sum_frequencies) / number_pixels\n",
    "    \n",
    "    # print(frequency_horizontal_lines, frequency_vertical_lines, ratio)\n",
    "    return frequency_horizontal_lines, frequency_vertical_lines, ratio\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\3\\\\0381.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\4\\\\0561.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\5\\\\746.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\6\\\\0941.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\7\\\\1121.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\8\\\\1306.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# hvsl_features(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_angle(image):\n",
    "    _unique, _count = np.unique(image, return_counts=True)\n",
    "    image_dict = dict(zip(_unique, _count))\n",
    "    \n",
    "    out_x = cv2.Sobel(image, cv2.CV_16S, 1, 0)\n",
    "    out_y = cv2.Sobel(image, cv2.CV_16S, 0, 1)\n",
    "    \n",
    "    out_x = cv2.convertScaleAbs(out_x)\n",
    "    out_y = cv2.convertScaleAbs(out_y)\n",
    "\n",
    "    dir = np.arctan2(out_y, out_x)\n",
    "    dir = np.multiply(dir, 180/np.pi)\n",
    "    \n",
    "    dir_unique, dir_count = np.unique(dir, return_counts=True)\n",
    "    \n",
    "    angle = np.sum(dir_unique * dir_count) / (np.sum(dir_count) - 2 * dir_count[0] + image_dict[1])\n",
    "    return np.radians(angle)\n",
    "     \n",
    "\n",
    "def text_orientation_features(skeleton_image, edge_image):\n",
    "    return sobel_angle(skeleton_image), sobel_angle(edge_image)\n",
    "    \n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\3\\\\0381.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\4\\\\0561.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\5\\\\746.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\6\\\\0941.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\7\\\\1121.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\8\\\\1306.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# text_orientation_features(x[2], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvl_features(skeleton_image):\n",
    "    # print(skeleton_image.shape)\n",
    "    thresh = cv2.threshold(skeleton_image, 0, 1, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Detect vertical lines\n",
    "    vertical_image = np.ones(skeleton_image.shape)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,10))\n",
    "    detect_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "    cnts = cv2.findContours(detect_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    cv2.drawContours(vertical_image, cnts, -1, (0, 0, 0))\n",
    "    \n",
    "    # show_images([vertical_image, skeleton_image])\n",
    "\n",
    "    vertical_image = np.where(vertical_image > 0, 0, 1)\n",
    "    vertical_lines = np.sum(vertical_image, axis=0)\n",
    "    v_unique, v_count = np.unique(vertical_lines, return_counts=True)\n",
    "    v_dict = dict(zip(v_unique, v_count))\n",
    "    \n",
    "    perimeter=[]\n",
    "    for cnt in cnts[1:]:\n",
    "        # perimeter.append(cv2.arcLength(cnt,False))\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        perimeter.append(h)\n",
    "    perimeter = np.asarray(perimeter)\n",
    "    \n",
    "    maximum_height = perimeter.max() if len(perimeter) != 0 else 0\n",
    "    \n",
    "    frequency_vertical_lines = skeleton_image.shape[1] - v_dict[0] if v_dict[0] != skeleton_image.shape[1] else 0\n",
    "    \n",
    "    inverted_img = np.where(skeleton_image > 0, 0, 1)\n",
    "    inverted_lines = np.sum(inverted_img, axis=1)\n",
    "    text_locations = np.argwhere(inverted_lines > 0)\n",
    "    text_height = text_locations.max() - text_locations.min()\n",
    "\n",
    "    ratio = (text_height - maximum_height) / text_height\n",
    "    variance = np.mean(vertical_lines)\n",
    "    \n",
    "    return text_height, frequency_vertical_lines, maximum_height, ratio, variance\n",
    "    \n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\3\\\\0381.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\4\\\\0561.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\5\\\\746.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\6\\\\0941.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\7\\\\1121.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\8\\\\1306.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# lvl_features(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tth_features(skeleton_image, edge_image):\n",
    "    # show_images([skeleton_image, edge_image, skeleton_image + edge_image])\n",
    "    pass\n",
    "    \n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# tth_features(x[2], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_features(diacritic_image):\n",
    "    thuluth_mohakik_sp_img = io.imread(\".\\\\special_diacritics.jpg\")\n",
    "    \n",
    "    thuluth_mohakik_sp_gs = rgb2gray(thuluth_mohakik_sp_img)\n",
    "    if thuluth_mohakik_sp_gs.max() <= 1:\n",
    "        thuluth_mohakik_sp_gs = (thuluth_mohakik_sp_gs * 255)\n",
    "    thuluth_mohakik_sp_gs = thuluth_mohakik_sp_gs.astype(np.uint8)\n",
    "    \n",
    "    global_threshold = threshold_otsu(thuluth_mohakik_sp_gs)\n",
    "    thuluth_mohakik_sp_bin_img = np.where(thuluth_mohakik_sp_gs > global_threshold, 1, 0)\n",
    "    \n",
    "    # print(np.unique(diacritic_image))\n",
    "    # print(np.unique(thuluth_mohakik_sp_bin_img))\n",
    "    \n",
    "    # show_images([thuluth_mohakik_sp_bin_img])\n",
    "    \n",
    "    thuluth_mohakik_sp_bin_img = thuluth_mohakik_sp_bin_img.astype(np.uint8)\n",
    "    d2 = cv2.matchShapes(diacritic_image, thuluth_mohakik_sp_bin_img, cv2.CONTOURS_MATCH_I3, 0)\n",
    "    \n",
    "    return d2\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\3\\\\0381.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\4\\\\0561.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\5\\\\746.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\6\\\\0941.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\7\\\\1121.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\8\\\\1306.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# sp_features(x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wor_features(text_image):\n",
    "    img = np.where(text_image > 0, 0, 1)\n",
    "    horizontal_projection = np.sum(img, axis = 1)\n",
    "    baseline_location_index = horizontal_projection.argmax()\n",
    "    img = np.copy(text_image)\n",
    "    previous_val = -1\n",
    "    current_val = text_image[baseline_location_index,:].argmin()\n",
    "    \n",
    "    angles = []\n",
    "    \n",
    "    while previous_val != current_val:\n",
    "        word = flood_fill(text_image, (baseline_location_index, current_val), 255)\n",
    "        img = flood_fill(img, (baseline_location_index, current_val), 255)\n",
    "        previous_val = current_val\n",
    "        current_val = img[baseline_location_index,:].argmin()\n",
    "        # ------------------------------------------------\n",
    "        word = np.where(word > 1, 1, 0)\n",
    "        word = word.astype(np.uint8)\n",
    "        # ------------------------------------------------\n",
    "        thresh = cv2.threshold(word, 1, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "        rows,cols = word.shape[:2]\n",
    "        [vx,vy,x,y] = cv2.fitLine(cnts[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "        lefty = int((-x*vy/vx) + y)\n",
    "        righty = int(((cols-x)*vy/vx)+y)\n",
    "        # cv2.line(word,(cols-1,righty),(0,lefty),1,2)\n",
    "        # ------------------------------------------------\n",
    "        angles.append(np.arctan2(righty - lefty, cols-1 - 0))\n",
    "\n",
    "        # show_images([word, img, text_image])\n",
    "        \n",
    "    angles = np.asarray(angles)\n",
    "    return angles.mean()\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\3\\\\0381.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\4\\\\0561.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\5\\\\746.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\6\\\\0941.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\7\\\\1121.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\8\\\\1306.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# wor_features(x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpp_features(text_image, window=50):  \n",
    "    invert_img = np.where(text_image > 0, 0, 1)   \n",
    "    invert_img = invert_img.astype(np.uint8)\n",
    "    \n",
    "    proj = np.sum(invert_img, axis=1)\n",
    "    proj = proj / proj.sum()\n",
    "    max_height = text_image.shape[0]\n",
    "    center = proj.argmax()\n",
    "\n",
    "    if center - window < 0 and center + window > max_height:\n",
    "        # BOTH\n",
    "        # print(\"BOTH\")\n",
    "        return np.concatenate((np.zeros(window - center), proj, np.zeros(center + window - max_height)))\n",
    "    elif center - window < 0 and center + window <= max_height:\n",
    "        # LEFT\n",
    "        # print(\"LEFT\")\n",
    "        return np.concatenate((np.zeros(window - center), proj[:center + window]))\n",
    "    elif center - window >= 0 and center + window > max_height:\n",
    "        # RIGHT\n",
    "        # print(\"RIGHT\")\n",
    "        return np.concatenate((proj[center - window:], np.zeros(center + window - max_height)))\n",
    "    else:\n",
    "        # NONE\n",
    "        # print(\"NONE\")\n",
    "        return proj[center - window:center + window]\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\2\\\\0191.jpg\")\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\9\\\\1496.jpg\")\n",
    "# x = preprocessing_image(img)\n",
    "# hpp = hpp_features(x[4], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(processed_images):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Calculating feature vector of an image\n",
    "    \n",
    "    INPUT:\n",
    "    binary_image, edge_image, skeleton_image, diacritic_image, text_image\n",
    "    \n",
    "    RETURN:\n",
    "    Array of features 1-D\n",
    "    '''\n",
    "    image_features = []\n",
    "    \n",
    "    frequency_horizontal_lines, frequency_vertical_lines, ratio = hvsl_features(processed_images[1])\n",
    "    image_features.append(frequency_horizontal_lines)\n",
    "    image_features.append(frequency_vertical_lines)\n",
    "    image_features.append(ratio)\n",
    "    \n",
    "    skeleton_direction, edge_direction = text_orientation_features(processed_images[2], processed_images[1])\n",
    "    image_features.append(skeleton_direction)\n",
    "    image_features.append(edge_direction)\n",
    "    \n",
    "    text_height, frequency_vertical_lines_2, maximum_height, ratio_2, variance = lvl_features(processed_images[2])\n",
    "    image_features.append(text_height)\n",
    "    image_features.append(frequency_vertical_lines_2)\n",
    "    image_features.append(maximum_height)\n",
    "    image_features.append(ratio_2)\n",
    "    image_features.append(variance)\n",
    "    \n",
    "    distance = sp_features(processed_images[3])\n",
    "    image_features.append(distance)\n",
    "    \n",
    "    angles = wor_features(processed_images[4])\n",
    "    image_features.append(angles)\n",
    "    \n",
    "    image_features = np.asarray(image_features)\n",
    "    \n",
    "    histogram_hpp = hpp_features(processed_images[4])\n",
    "    image_features = np.concatenate((image_features, histogram_hpp))\n",
    "    \n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_training_validating(base_directory, training_percent):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Get array of images at specific directory. Directory is divied into M-sections. \n",
    "    Each section is divided in N-fonts. Then preprocess, extract features\n",
    "    \n",
    "    RETURN:\n",
    "    Array of N-fonts of arrays of features/image\n",
    "    [\n",
    "        Font_X[\n",
    "            FeatureImg1[...]\n",
    "            FeatureImg2[...]\n",
    "            FeatureImg3[...]\n",
    "            ...\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    training_features = [[] for x in range(0,9)]\n",
    "    validating_features = [[] for x in range(0,9)]\n",
    "    true_validation = [[] for x in range(0,9)]\n",
    "    features = [[] for x in range(0,9)]\n",
    "    for folder_num in range(1, 10):\n",
    "        folder_path = base_directory + \"\\\\\" + str(folder_num)\n",
    "        filenames = os.listdir(folder_path)\n",
    "        \n",
    "        for fn in filenames:\n",
    "            path = os.path.join(folder_path, fn)\n",
    "            img = io.imread(path)\n",
    "            preprocessed_image = preprocessing_image(img)\n",
    "            image_features = extract_features(preprocessed_image)\n",
    "            features[folder_num - 1].append(image_features)\n",
    "            \n",
    "        features[folder_num - 1] = np.asarray(features[folder_num - 1])\n",
    "        n_training = round(features[folder_num - 1].shape[0] * training_percent)\n",
    "        training_features[folder_num - 1] = features[folder_num - 1][:n_training]\n",
    "        validating_features[folder_num - 1] = features[folder_num - 1][n_training:]\n",
    "        true_validation[folder_num - 1] = np.full((features[folder_num - 1][n_training:].shape[0], 1), folder_num)\n",
    "        \n",
    "    return np.asarray(training_features), np.asarray(validating_features), np.asarray(true_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"..\\\\..\\\\data\\\\raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar_\\AppData\\Local\\Temp/ipykernel_17928/2810286816.py:14: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  grayscale_image = rgb2gray(img)\n",
      "C:\\Users\\omar_\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# (9,(percentage, [features]))\n",
    "training_features, validating_features, true_validation = features_training_validating(base_directory, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"training_data.csv\",\"w\").close()\n",
    "for class_idx, class_features in enumerate(training_features):\n",
    "    true_class = np.full((class_features.shape[0], 1), class_idx + 1)\n",
    "    with open('training_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, np.concatenate((true_class, np.asarray(class_features)), axis=1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"validating_data.csv\",\"w\").close()\n",
    "open(\"true_validating_data.csv\",\"w\").close()\n",
    "for class_idx, class_features in enumerate(validating_features):\n",
    "    with open('validating_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, class_features, delimiter=\",\")\n",
    "    \n",
    "    with open('true_validating_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, true_validation[class_idx], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_names = ['diwani', 'naskh', 'parsi', 'rekaa', 'thuluth', 'maghribi', 'kufi', 'mohakek', 'Squar-kufic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.asarray(read_data('training_data.csv'))\n",
    "test_data, test_data_true = read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClasses = 9\n",
    "M = len(training_data)\n",
    "N = len(test_data[0])\n",
    "K = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(training_data)[:, 1:N + 1]\n",
    "X_Test = np.asarray(test_data)\n",
    "Y = np.asarray(training_data)[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 33.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar_\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=10)\n",
    "clf.fit(X, Y)\n",
    "prediction_classes = clf.predict(X_Test)\n",
    "numpy_predicted_classes = np.array(prediction_classes)\n",
    "numpy_true_test_data = np.array(test_data_true)\n",
    "\n",
    "accuracy = sum(numpy_true_test_data == numpy_predicted_classes) / K\n",
    "print('Accuracy = ' + str(round(accuracy,4) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      diwani       0.73      0.50      0.59        38\n",
      "       naskh       0.19      1.00      0.32        38\n",
      "       parsi       0.00      0.00      0.00        36\n",
      "       rekaa       0.17      0.03      0.05        37\n",
      "     thuluth       0.75      0.23      0.35        39\n",
      "    maghribi       0.00      0.00      0.00        36\n",
      "        kufi       0.44      0.41      0.42        37\n",
      "     mohakek       0.05      0.03      0.03        38\n",
      " Squar-kufic       1.00      0.76      0.87        38\n",
      "\n",
      "    accuracy                           0.33       337\n",
      "   macro avg       0.37      0.33      0.29       337\n",
      "weighted avg       0.37      0.33      0.30       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(numpy_true_test_data, numpy_predicted_classes, target_names=font_names))\n",
    "# print((Y.reshape(1, -1)[0] - 1).shape)\n",
    "# print((numpy_predicted_classes - 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 3)\n",
      "(1348, 1)\n",
      "(1348, 1)\n",
      "(1348, 5)\n",
      "(1348, 1)\n",
      "(1348, 1)\n",
      "(1348, 1)\n"
     ]
    }
   ],
   "source": [
    "# clf = svm.SVC(kernel='poly', random_state=0)\n",
    "# clf.fit(X[], Y)\n",
    "# prediction_classes = clf.predict(X_Test)\n",
    "\n",
    "# print(X)\n",
    "# HVSL\n",
    "print(X[:, [0,1,2]].shape)\n",
    "clf_hvsl = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# ToS\n",
    "print(X[:, [3]].shape)\n",
    "clf_tos = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# ToE\n",
    "print(X[:, [4]].shape)\n",
    "clf_toe = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# LVL\n",
    "print(X[:, [5,6,7,8,9]].shape)\n",
    "clf_lvl = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# SP\n",
    "print(X[:, [10]].shape)\n",
    "clf_sp = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# WOr\n",
    "print(X[:, [11]].shape)\n",
    "clf_wor = svm.SVC(kernel='poly', random_state=0, probability=True)\n",
    "# HPP\n",
    "print(X[:, [12]].shape)\n",
    "clf_hpp = svm.SVC(kernel='poly', random_state=0, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 31.75%\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('svm1', clf_hvsl), ('svm2', clf_toe), ('svm3', clf_tos),\n",
    "                                    ('svm4', clf_lvl), ('svm6', clf_sp), ('svm7', clf_wor),\n",
    "                                    ('svm8', clf_hpp)], voting='soft', n_jobs=-1)\n",
    "\n",
    "# clf_hvsl.fit(X[:, [0,1,2]], Y.ravel()).predict(X_Test[:, [0,1,2]])\n",
    "# clf_tos.fit(X[:, [3]], Y.ravel()).predict(X_Test[:, [3]])\n",
    "# clf_toe.fit(X[:, [4]], Y.ravel()).predict(X_Test[:, [4]])\n",
    "# clf_lvl.fit(X[:, [5,6,7,8,9]], Y.ravel()).predict(X_Test[:, [5, 6, 7, 8, 9]])\n",
    "# clf_sp.fit(X[:, [10]], Y.ravel()).predict(X_Test[:, [10]])\n",
    "# clf_wor.fit(X[:, [11]], Y.ravel()).predict(X_Test[:, [11]])\n",
    "# clf_hpp.fit(X[:, 12:], Y.ravel()).predict(X_Test[:, 12:])\n",
    "\n",
    "eclf.fit(X, Y.ravel())\n",
    "\n",
    "prediction_classes = eclf.predict(X_Test)\n",
    "numpy_predicted_classes = np.array(prediction_classes)\n",
    "numpy_true_test_data = np.array(test_data_true)\n",
    "\n",
    "accuracy = sum(numpy_true_test_data == numpy_predicted_classes) / K\n",
    "print('Accuracy = ' + str(round(accuracy,4) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2bd8c26a442d44da6f77d71c63a5d5ec634807a3105e8450172857d10d915d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
