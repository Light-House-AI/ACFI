{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Paper\n",
    "## A Statistical Global Feature Extraction Method for Optical Font Recognition\n",
    "---\n",
    "[Click here](https://link.springer.com/content/pdf/10.1007%2F978-3-642-20039-7_26.pdf) to open the research paper.\n",
    "\n",
    "### Research paper summary\n",
    "We divide the framework of Arabic Calligraphy font recognition system into two\n",
    "parts: preprocessing and post-processing modules. In the pre-processing, besides\n",
    "generating texture blocks of the predetermined text, we also include edge deduction\n",
    "process. Whilst the post processing involves two sub processes such as feature\n",
    "extraction using our proposed algorithm based on statistical method and recognition\n",
    "sub processes.\n",
    "\n",
    "<table id=\"table-description\">\n",
    "    <style>\n",
    "        table td:nth-child(2), table th:nth-child(2) { text-align: center; }\n",
    "        #table-description {width:70%;}\n",
    "    </style>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Modules</th>\n",
    "            <th>Description</th>\n",
    "            <th>Done</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Preprocessing</td>\n",
    "            <td>\n",
    "                <ol style=\"padding-right:15px;\">\n",
    "                    <li>Binarization</li>\n",
    "                    <li>Skew correction</li>\n",
    "                    <li>Text normalization</li>\n",
    "                    <li>Laplacian filter</li>\n",
    "                    <li>Set size 512x512</li>\n",
    "                </ol>\n",
    "            </td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "                    <li>&#x2611;</li>\n",
    "                    <li>&#x2612;</li>\n",
    "                    <li>&#x2612;</li>\n",
    "                    <li>&#x2611;</li>\n",
    "                    <li>&#x2612;</li>\n",
    "                </ul>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Postprocessing</td>\n",
    "            <td>\n",
    "                <ol style=\"padding-right:15px;\">\n",
    "<li>1st order relationship EDM<sub>1</sub></li><li>Proposed sorted EDM<sub>1</sub></li><li>2nd order relationship EDM<sub>2</sub></li>\n",
    "                </ol>\n",
    "            </td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "                    <li>&#x2611;</li><li>&#x2611;</li><li>&#x2611;</li>\n",
    "                </ul>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Feature Extraction</td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "<li>Edges Direction</li><li>Homogeneity θ</li><li>Weight</li><li>Pixel Regularity θ</li><li>Edges Regularity θ<sub>*</sub></li>\n",
    "                </ul>\n",
    "            </td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "                    <li>&#x2611;</li><li>&#x2611;</li><li>&#x2611;</li><li>&#x2611;</li><li>&#x2611;</li>\n",
    "                </ul>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Classifications</td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "<li>Bayes network</li><li>Multilayer Network</li><li>Decision Tree</li>\n",
    "                </ul>\n",
    "            </td>\n",
    "            <td>\n",
    "                <ul style=\"list-style-type:none;padding:0;margin-left:5px;margin-right:5px;\">\n",
    "                    <li>&#x2612;</li><li>&#x2612;</li><li>&#x2611;</li>\n",
    "                </ul>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "#### θ,θ<sub>*</sub> Description\n",
    "\n",
    "| θ Type | Value |\n",
    "|:---:|:---:|\n",
    "| θ | 0°, 45°, 90°, 135° |\n",
    "| θ<sub>*</sub> | 0°, 45°, 90°, 135°,180°, 225° |\n",
    "\n",
    "#### Paper experiment results\n",
    "\n",
    "| Classifier | Accuracy |\n",
    "|:---:|:---:|\n",
    "| Bayes network  | 92.473% |\n",
    "| Multilayer Network | 95.341% |\n",
    "| Decision Tree | 97.85% |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports you will need in the whole lab\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.exposure import histogram\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import bar\n",
    "import cv2\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "def showHist(img):\n",
    "    # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "    \n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    ## HINT 1: How is the data ordered in the file?\n",
    "    ## HINT 2: Do you need to cast the data you read from the file?\n",
    "    data = []\n",
    "    with open(file_name, newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            data.append([float(element) for element in row[0].split(',')])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data():\n",
    "    \n",
    "    # TODO [2.A]: Read the file 'test_data.csv' into the variable test_data\n",
    "    # test_data contains the unlabelled test class.\n",
    "    ## HINT: Do you need to cast the data you read from the file?\n",
    "\n",
    "    test_data = read_data('test_data.csv')\n",
    "    \n",
    "    # TODO [2.B]: Read the file 'test_data_true.csv' into the variable test_data_true\n",
    "    # test_data_true contains the actual classes of the test instances, which you will compare\n",
    "    # against your predicted classes.\n",
    "    ## HINT: Do you need to cast the data you read from the file?\n",
    "\n",
    "    test_data_true = []\n",
    "    with open('./test_data_true.csv', newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            test_data_true.append(float(row[0]))\n",
    "            \n",
    "    return test_data, test_data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_folder(base_directory, sections, number_of_fonts):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Get array of images at specific directory. Directory is divied into M-sections. \n",
    "    Each section is divided in N-fonts\n",
    "    \n",
    "    RETURN:\n",
    "    Array of N-fonts of arrays of images\n",
    "    '''\n",
    "    images = [[] for x in range(number_of_fonts)]\n",
    "    for section_num in sections:\n",
    "        for folder_num in range(1, number_of_fonts + 1):\n",
    "            folder_path = base_directory + \"\\\\section\" + str(section_num) + \"\\\\\" + str(folder_num)\n",
    "            filenames = os.listdir(folder_path)\n",
    "            \n",
    "            font_images = []\n",
    "            for fn in filenames:\n",
    "                path = os.path.join(folder_path, fn)\n",
    "                img = io.imread(path)            \n",
    "                font_images.append(img)\n",
    "            \n",
    "            images[section_num - 1] += font_images\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_image_folder(base_directory, sections, number_of_fonts):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Get array of images at specific directory. Directory is divied into M-sections. \n",
    "    Each section is divided in N-fonts. Then preprocess, extract features\n",
    "    \n",
    "    RETURN:\n",
    "    Array of N-fonts of arrays of features/image\n",
    "    [\n",
    "        Font_X[\n",
    "            FeatureImg1[...]\n",
    "            FeatureImg2[...]\n",
    "            FeatureImg3[...]\n",
    "            ...\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    features = [[] for x in range(number_of_fonts)]\n",
    "    for section_num in sections:\n",
    "        for folder_num in range(1, number_of_fonts + 1):\n",
    "            folder_path = base_directory + \"\\\\section\" + str(section_num) + \"\\\\\" + str(folder_num)\n",
    "            filenames = os.listdir(folder_path)\n",
    "            \n",
    "            for fn in filenames:\n",
    "                path = os.path.join(folder_path, fn)\n",
    "                img = io.imread(path)\n",
    "                preprocessed_image = preprocessing_image(img)\n",
    "                image_features = proposed_method(preprocessed_image)\n",
    "                features[folder_num - 1].append(image_features)\n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(img):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Preprocess an image.\n",
    "        1. Grayscale\n",
    "        2. OTSU Threshold\n",
    "        3. Binarization\n",
    "        4. Checking image binary is 0 or 255\n",
    "        5. Laplacian filter\n",
    "    \n",
    "    RETURN:\n",
    "    Preprocessd Image\n",
    "    '''\n",
    "    grayscale_image = rgb2gray(img)\n",
    "    if grayscale_image.max() <= 1:\n",
    "        grayscale_image = (grayscale_image * 255)\n",
    "    grayscale_image = grayscale_image.astype(np.uint8)\n",
    "    \n",
    "    global_threshold = threshold_otsu(grayscale_image)\n",
    "    binary_image = np.where(grayscale_image > global_threshold, 255, 0)\n",
    "    # binary_image = grayscale_image > global_threshold\n",
    "    \n",
    "    image_histogram = np.asarray(histogram(binary_image, nbins=256))\n",
    "    if image_histogram.argmax() <= 150:\n",
    "        binary_image = 255 - binary_image\n",
    "    binary_image = binary_image.astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    laplacian_image = cv2.convertScaleAbs(cv2.Laplacian(binary_image, cv2.CV_16S, ksize=3))\n",
    "    laplacian_image = 255 - laplacian_image\n",
    "    # show_images([grayscale_image, binary_image, laplacian_image], ['GRAYSCALE', 'BINARY', 'SAMPLE'])\n",
    "    # showHist(laplacian_image)\n",
    "    return laplacian_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_edm(edm):\n",
    "    ''' \n",
    "    DESCRIPTION:\n",
    "        Angles\n",
    "        135   90   45\n",
    "        180   c     0\n",
    "        225  270  315\n",
    "        --------------\n",
    "        1D\n",
    "        0 45 90 135 180 225 270 315\n",
    "        Index\n",
    "        0 1  2  3   4   5   6   7\n",
    "    \n",
    "    RETURN:\n",
    "    Proposed sorted Array\n",
    "    '''\n",
    "    \n",
    "    edm_1 = [(0, edm[1, 2]), (45, edm[0, 2]), (90, edm[0, 1]), (135, edm[0, 0]),\n",
    "             (180, edm[1, 0]), (225, edm[2, 0]), (270, edm[2, 1]), (315, edm[2, 2])]\n",
    "    \n",
    "    edm_sorted = np.asarray(sorted(edm_1, key=lambda x:x[1], reverse=True))\n",
    "    \n",
    "    for i in range(1, 8, 2):\n",
    "        subsquent_angle = edm_sorted[i - 1, 0] + 180 if edm_sorted[i - 1, 0] + 180 < 360 else edm_sorted[i - 1, 0] - 180\n",
    "        subsquent_angle_index = np.where(edm_sorted[:,0] == subsquent_angle)[0][0]\n",
    "\n",
    "        if edm_sorted[i, 0] != edm_sorted[subsquent_angle_index, 0]:\n",
    "            edm_sorted[[i, subsquent_angle_index]] = edm_sorted[[subsquent_angle_index, i]]\n",
    "            \n",
    "    return edm_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_direction_matrix(image):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Takes an image. Calculates EDM-1\n",
    "    \n",
    "    RETURN:\n",
    "    Edge Direction Matrix-1, Sum of Black Pixel in Iedge\n",
    "    '''\n",
    "    \n",
    "    padded_image = np.pad(image, 1, 'constant', constant_values=[1])\n",
    "    padded_image = np.where(padded_image > 0, 0, 1)\n",
    "    edm = np.zeros((3,3))\n",
    "    black_pixels = 0\n",
    "    for i in range(1, padded_image.shape[0] - 1):\n",
    "        for j in range(1, padded_image.shape[1] - 1):\n",
    "            if padded_image[i, j] == 1:\n",
    "                edm += padded_image[i-1:i+2, j-1:j+2]\n",
    "                black_pixels += padded_image[i-1:i+2, j-1:j+2].reshape(1, -1).sum()\n",
    "    return edm, black_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_direction_matrix_2(image, edm_1):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Takes an image and EDM-1. Calculates EDM-2\n",
    "    \n",
    "    RETURN:\n",
    "    Edge Direction Matrix-2\n",
    "    '''\n",
    "    \n",
    "    angles = np.asarray([\n",
    "        [135, 90, 45],\n",
    "        [180, -1, 0],\n",
    "        [225, 270, 315]\n",
    "    ])\n",
    "    relationship_order = sort_edm(edm_1)\n",
    "    edm_2 = np.zeros((3,3))\n",
    "    padded_image = np.pad(image, 1, 'constant', constant_values=[1])\n",
    "    padded_image = np.where(padded_image > 0, 0, 1)\n",
    "    for i in range(1, padded_image.shape[0] - 1):\n",
    "        for j in range(1, padded_image.shape[1] - 1):\n",
    "            if padded_image[i, j] == 1:\n",
    "                edm_2[1, 1] += 1\n",
    "                edge_found = []\n",
    "                if padded_image[i, j + 1] == 1:\n",
    "                    # angle 180\n",
    "                    rs_index = np.where(relationship_order[:,0] == 180)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0, 0], relationship_order[rs_index][0, 1], rs_index))\n",
    "                if padded_image[i - 1, j + 1] == 1:\n",
    "                    # angle 225\n",
    "                    rs_index = np.where(relationship_order[:,0] == 225)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0, 0], relationship_order[rs_index][0, 1], rs_index))\n",
    "                if padded_image[i - 1, j] == 1:\n",
    "                    # angle 270\n",
    "                    rs_index = np.where(relationship_order[:,0] == 270)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                if padded_image[i - 1, j - 1] == 1:\n",
    "                    # angle 315\n",
    "                    rs_index = np.where(relationship_order[:,0] == 315)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                if padded_image[i, j - 1] == 1:\n",
    "                    # angle 0\n",
    "                    rs_index = np.where(relationship_order[:,0] == 0)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                if padded_image[i + 1, j - 1] == 1:\n",
    "                    # angle 45\n",
    "                    rs_index = np.where(relationship_order[:,0] == 45)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                if padded_image[i + 1, j] == 1:\n",
    "                    # angle 90\n",
    "                    rs_index = np.where(relationship_order[:,0] == 90)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                if padded_image[i + 1, j + 1] == 1:\n",
    "                    # angle 135\n",
    "                    rs_index = np.where(relationship_order[:,0] == 135)[0]\n",
    "                    edge_found.append((relationship_order[rs_index][0][0], relationship_order[rs_index][0][1], rs_index))\n",
    "                # -----------------------------------------------------------  \n",
    "                edge_found = sorted(edge_found, key=lambda x:x[2])\n",
    "                edge_found = sorted(edge_found, key=lambda x:x[1], reverse=True)\n",
    "                angle_to_increment = edge_found[0][0]\n",
    "                \n",
    "                x, y = np.argwhere(angles == angle_to_increment)[0]\n",
    "                edm_2[x, y] += 1\n",
    "    return edm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_edms(edm_1, edm_2, sum_black_pixels):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Calculating feature vector of an image\n",
    "    \n",
    "    RETURN:\n",
    "    Array of features 1-D\n",
    "    '''\n",
    "    image_features = []\n",
    "    \n",
    "    pivot_edm_1 = edm_1[1, 1]\n",
    "    pivot_edm_2 = edm_2[1, 1]\n",
    "    \n",
    "    edm_1_1d = np.asarray(edm_1.reshape(1, -1))[0]\n",
    "    edm_1_1d = np.delete(edm_1_1d, 4)\n",
    "    \n",
    "    edm_2_1d = np.asarray(edm_2.reshape(1, -1))[0]\n",
    "    edm_2_1d = np.delete(edm_2_1d, 4)\n",
    "    \n",
    "    sub_edm_1 = np.asarray([edm_1[1, 2], edm_1[0, 2], edm_1[0, 1], edm_1[0, 0]])\n",
    "    # Feature 1\n",
    "    edges_direction = edm_1_1d.max()\n",
    "    image_features.append(edges_direction)\n",
    "    # Feature 2, 3, 4, 5\n",
    "    homogeneity = sub_edm_1 / sum(edm_1.reshape(1, -1)[0])\n",
    "    for idx, h in enumerate(homogeneity):\n",
    "        image_features.append(h)\n",
    "    # Feature 6\n",
    "    weight = pivot_edm_1 / sum_black_pixels\n",
    "    image_features.append(weight)\n",
    "    # Feature 7, 8, 9, 10\n",
    "    pixel_regularity = sub_edm_1 / pivot_edm_1\n",
    "    for idx, px_reg in enumerate(pixel_regularity):\n",
    "        image_features.append(px_reg)\n",
    "    # Feature 11, 12, 13, 14, 15, 16, 17, 18\n",
    "    edges_regularity = edm_2_1d / pivot_edm_2\n",
    "    \n",
    "    for idx, ed_reg in enumerate(edges_regularity):\n",
    "        image_features.append(ed_reg)\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_method(image):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Feature Extraction Module\n",
    "    \n",
    "    RETURN:\n",
    "    Array of features 1-D\n",
    "    '''\n",
    "    \n",
    "    edm_1, sum_black_pixels = edge_direction_matrix(image)\n",
    "    edm_2 = edge_direction_matrix_2(image, edm_1)\n",
    "    return extract_features_edms(edm_1, edm_2, sum_black_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validating feature extraction of the research paper\n",
    "'''\n",
    "\n",
    "image = [\n",
    "    [1, 0, 0, 0, 1, 1],\n",
    "    [0, 1, 1, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1, 0],\n",
    "    [1, 1, 1, 0, 0, 1]]\n",
    "\n",
    "image = np.asarray(image)\n",
    "# print(sort_edm(edge_direction_matrix(image)))\n",
    "edm_1, sum_black_pixels = edge_direction_matrix(image)\n",
    "edm_2 = edge_direction_matrix_2(image, edm_1)\n",
    "print(edm_1, sum_black_pixels)\n",
    "print(edm_2)\n",
    "print(extract_features_edms(edm_1, edm_2, sum_black_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying of make a pipeline with ACdata_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of fonts\n",
    "nClasses = 9\n",
    "base_directory = \".\\\\Dataset_Analyzed\\\\\"\n",
    "# Training sections\n",
    "training_sections = [1, 2, 3, 4]\n",
    "# Validating sections\n",
    "validating_sections = [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BELOW 2 CELLS NOT USED\n",
    "TRIED TO USED `read_image_folder()`\n",
    "\n",
    "SOMETHING WENT WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all training images\n",
    "training_images = read_image_folder(base_directory, training_sections, nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing training images & Extract Features\n",
    "training_features = []\n",
    "for class_number, class_images in enumerate(training_images):\n",
    "    print(class_number)\n",
    "    for image in class_images:\n",
    "        preprocessed_image = preprocessing_image(image)\n",
    "        image_features = proposed_method(preprocessed_image)\n",
    "        training_features.append([class_number + 1] + image_features)\n",
    "    print(\"CLASS\", str(class_number + 1) + \":\", \"FINISHED\")\n",
    "\n",
    "with open('training_data.txt', 'a') as csvfile:\n",
    "    np.savetxt(csvfile, np.asarray(training_features), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXTRACTED ALL TRAINING FEATURES & SAVE IN CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9,[])\n",
    "training_features = extract_feature_image_folder(base_directory, training_sections, nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, class_features in enumerate(training_features):\n",
    "    print(idx)\n",
    "    for image_feature in enumerate(class_features):\n",
    "        with open('training_data.csv', 'a') as csvfile:\n",
    "            np.savetxt(csvfile, np.asarray([[idx + 1] + image_feature[1]]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXTRACTED ALL VALIDATING FEATURES & SAVE IN CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_feature_image_folder(base_directory, validating_sections, nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, class_features in enumerate(test_features):\n",
    "    print(idx)\n",
    "    for image_feature in enumerate(class_features):\n",
    "        with open('test_data.csv', 'a') as csvfile:\n",
    "            np.savetxt(csvfile, np.asarray([image_feature[1]]), delimiter=\",\")\n",
    "        with open('true_classification.txt', 'a') as csvfile:\n",
    "            np.savetxt(csvfile, np.asarray([idx + 1]), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2bd8c26a442d44da6f77d71c63a5d5ec634807a3105e8450172857d10d915d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
