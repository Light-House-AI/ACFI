{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB, ComplementNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from skimage.exposure import histogram\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu, laplace\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "def showHist(img):\n",
    "    # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "    \n",
    "    plt.bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    ## HINT 1: How is the data ordered in the file?\n",
    "    ## HINT 2: Do you need to cast the data you read from the file?\n",
    "    data = []\n",
    "    with open(file_name, newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            data.append([float(element) for element in row[0].split(',')])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data():\n",
    "    \n",
    "    # TODO [2.A]: Read the file 'test_data.csv' into the variable test_data\n",
    "    # test_data contains the unlabelled test class.\n",
    "    ## HINT: Do you need to cast the data you read from the file?\n",
    "\n",
    "    test_data = read_data('validating_data.csv')\n",
    "    \n",
    "    # TODO [2.B]: Read the file 'test_data_true.csv' into the variable test_data_true\n",
    "    # test_data_true contains the actual classes of the test instances, which you will compare\n",
    "    # against your predicted classes.\n",
    "    ## HINT: Do you need to cast the data you read from the file?\n",
    "\n",
    "    test_data_true = []\n",
    "    with open('./true_validating_data.csv', newline='') as csv_file:\n",
    "        spamreader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            test_data_true.append(float(row[0]))\n",
    "            \n",
    "    return test_data, test_data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(img):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Preprocess an image.\n",
    "        1. Grayscale\n",
    "        2. OTSU Threshold\n",
    "        3. Binarization\n",
    "        4. Checking image binary is 0 or 255\n",
    "        5. Laplacian filter\n",
    "    \n",
    "    RETURN:\n",
    "    Preprocessd Image\n",
    "    '''\n",
    "    grayscale_image = rgb2gray(img)\n",
    "    if grayscale_image.max() <= 1:\n",
    "        grayscale_image = (grayscale_image * 255)\n",
    "    grayscale_image = grayscale_image.astype(np.uint8)\n",
    "    \n",
    "    global_threshold = threshold_otsu(grayscale_image)\n",
    "    binary_image = np.where(grayscale_image > global_threshold, 255, 0)\n",
    "    # binary_image = grayscale_image > global_threshold\n",
    "    \n",
    "    image_histogram = np.asarray(histogram(binary_image, nbins=256))\n",
    "    if image_histogram.argmax() <= 150:\n",
    "        binary_image = 255 - binary_image\n",
    "    binary_image = np.where(binary_image > 0, 0, 1)\n",
    "    binary_image = binary_image.astype(np.uint8)\n",
    "    \n",
    "    # show_images([binary_image])\n",
    "    return binary_image\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# processed = preprocessing_image(img)\n",
    "# x = lpq(processed,winSize=3,freqestim=3,mode='nh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpq(img, winSize=3, freqestim=1):\n",
    "\n",
    "    # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "    STFTalpha = 1/winSize\n",
    "    # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "    sigmaS = (winSize-1)/4\n",
    "    # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "    sigmaA = 8/(winSize-1)\n",
    "\n",
    "    # Compute descriptor responses only on part that have full neigborhood.\n",
    "    # Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "    convmode = 'valid'\n",
    "\n",
    "    # Convert np.image to double\n",
    "    img = np.float64(img)\n",
    "    # Get radius from window size\n",
    "    r = (winSize-1)/2\n",
    "    # Form spatial coordinates in window\n",
    "    x = np.arange(-r, r+1)[np.newaxis]\n",
    "\n",
    "    u = np.arange(1, r+1)\n",
    "\n",
    "    # STFT uniform window\n",
    "    if freqestim == 1:\n",
    "        #  Basic STFT filters\n",
    "        w0 = np.ones_like(x)\n",
    "        w1 = np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2 = np.conj(w1)\n",
    "    # STFT Gaussian window (equals to Gaussian quadrature filter pair)\n",
    "    elif freqestim == 2:\n",
    "        # Basic STFT filters\n",
    "        w0 = (x * 0 + 1)\n",
    "        w1 = np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2 = np.conj(w1)\n",
    "        # Gaussian window\n",
    "        gs = np.exp(- 0.5 * (x / sigmaS) ** 2) / \\\n",
    "            (np.multiply(np.sqrt(2 * np.pi), sigmaS))\n",
    "        # Windowed filters\n",
    "        w0 = np.multiply(gs, w0)\n",
    "        w1 = np.multiply(gs, w1)\n",
    "        w2 = np.multiply(gs, w2)\n",
    "        # Normalize to zero mean\n",
    "        w1 = w1 - np.mean(w1)\n",
    "        w2 = w2 - np.mean(w2)\n",
    "    # Gaussian derivative quadrature filter pair\n",
    "    elif freqestim == 3:\n",
    "\n",
    "        G0 = np.exp(- x ** 2 * (np.sqrt(2) * sigmaA) ** 2)\n",
    "\n",
    "        G1_zeros = np.concatenate((np.zeros(len(u)), np.asarray([0])))\n",
    "        G1 = np.asarray(\n",
    "            [np.concatenate((G1_zeros, u * np.exp(- u ** 2 * sigmaA ** 2)))])\n",
    "        \n",
    "        # Normalize to avoid small numerical values (do not change the phase response we use)\n",
    "        G0 = G0 / np.max(np.abs(G0))\n",
    "        G1 = G1 / np.max(np.abs(G1))\n",
    "        \n",
    "        # Compute spatial domain correspondences of the filters\n",
    "        w0 = np.real(np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(G0))))\n",
    "        w1 = np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(G1)))\n",
    "        w2 = np.conj(w1)\n",
    "        \n",
    "        # Normalize to avoid small numerical values (do not change the phase response we use)\n",
    "        w0 = w0 / \\\n",
    "            np.max(\n",
    "                np.abs(np.array([np.real(np.max(w0)), np.imag(np.max(w0))])))\n",
    "        w1 = w1 / \\\n",
    "            np.max(\n",
    "                np.abs(np.array([np.real(np.max(w1)), np.imag(np.max(w1))])))\n",
    "        w2 = w2 / \\\n",
    "            np.max(\n",
    "                np.abs(np.array([np.real(np.max(w2)), np.imag(np.max(w2))])))\n",
    "\n",
    "    # Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "    # Run first filter\n",
    "    filterResp1 = convolve2d(convolve2d(img, w0.T, convmode), w1, convmode)\n",
    "    filterResp2 = convolve2d(convolve2d(img, w1.T, convmode), w0, convmode)\n",
    "    filterResp3 = convolve2d(convolve2d(img, w1.T, convmode), w1, convmode)\n",
    "    filterResp4 = convolve2d(convolve2d(img, w1.T, convmode), w2, convmode)\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "    freqResp = np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                          filterResp2.real, filterResp2.imag,\n",
    "                          filterResp3.real, filterResp3.imag,\n",
    "                          filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    # Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis, np.newaxis, :]\n",
    "    LPQdesc = ((freqResp > 0)*(2**inds)).sum(2)\n",
    "\n",
    "    LPQdesc = np.histogram(LPQdesc.flatten(), range(256))[0]\n",
    "\n",
    "    LPQdesc = LPQdesc/LPQdesc.sum()\n",
    "\n",
    "    return LPQdesc\n",
    "\n",
    "# img = io.imread(\"..\\\\..\\\\data\\\\raw\\\\1\\\\0001.jpg\")\n",
    "# processed = preprocessing_image(img)\n",
    "# x = lpq(processed,winSize=3,freqestim=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_training_validating(base_directory, training_percent):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Get array of images at specific directory. Directory is divied into M-sections. \n",
    "    Each section is divided in N-fonts. Then preprocess, extract features\n",
    "    \n",
    "    RETURN:\n",
    "    Array of N-fonts of arrays of features/image\n",
    "    [\n",
    "        Font_X[\n",
    "            FeatureImg1[...]\n",
    "            FeatureImg2[...]\n",
    "            FeatureImg3[...]\n",
    "            ...\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    training_features = [[] for x in range(0,9)]\n",
    "    validating_features = [[] for x in range(0,9)]\n",
    "    true_validation = [[] for x in range(0,9)]\n",
    "    features = [[] for x in range(0,9)]\n",
    "    for folder_num in range(1, 10):\n",
    "        folder_path = base_directory + \"\\\\\" + str(folder_num)\n",
    "        filenames = os.listdir(folder_path)\n",
    "        \n",
    "        for fn in filenames:\n",
    "            path = os.path.join(folder_path, fn)\n",
    "            img = io.imread(path)\n",
    "            preprocessed_image = preprocessing_image(img)\n",
    "            image_features = lpq(preprocessed_image,winSize=3,freqestim=2)\n",
    "            features[folder_num - 1].append(image_features)\n",
    "            \n",
    "        features[folder_num - 1] = np.asarray(features[folder_num - 1])\n",
    "        n_training = round(features[folder_num - 1].shape[0] * training_percent)\n",
    "        training_features[folder_num - 1] = features[folder_num - 1][:n_training]\n",
    "        validating_features[folder_num - 1] = features[folder_num - 1][n_training:]\n",
    "        true_validation[folder_num - 1] = np.full((features[folder_num - 1][n_training:].shape[0], 1), folder_num)\n",
    "        \n",
    "    return np.asarray(training_features), np.asarray(validating_features), np.asarray(true_validation)\n",
    "\n",
    "# training_features, validating_features, true_validation = features_training_validating(\"..\\\\..\\\\data\\\\raw\", 1.0)\n",
    "# print(training_features[0].shape, validating_features[0].shape, true_validation[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar_\\AppData\\Local\\Temp/ipykernel_13164/778711977.py:14: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  grayscale_image = rgb2gray(img)\n",
      "C:\\Users\\omar_\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "base_directory = \"..\\\\..\\\\data\\\\raw\"\n",
    "training_features, validating_features, true_validation = features_training_validating(base_directory, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"training_data.csv\",\"w\").close()\n",
    "for class_idx, class_features in enumerate(training_features):\n",
    "    true_class = np.full((class_features.shape[0], 1), class_idx + 1)\n",
    "    with open('training_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, np.concatenate((true_class, np.asarray(class_features)), axis=1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"validating_data.csv\",\"w\").close()\n",
    "open(\"true_validating_data.csv\",\"w\").close()\n",
    "for class_idx, class_features in enumerate(validating_features):\n",
    "    with open('validating_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, class_features, delimiter=\",\")\n",
    "    \n",
    "    with open('true_validating_data.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, true_validation[class_idx], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_names = ['diwani', 'naskh', 'parsi', 'rekaa', 'thuluth', 'maghribi', 'kufi', 'mohakek', 'Squar-kufic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.asarray(read_data('training_data.csv'))\n",
    "test_data, test_data_true = read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClasses = 9\n",
    "M = len(training_data)\n",
    "N = len(test_data[0])\n",
    "K = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(training_data)[:, 1:N + 1]\n",
    "X_Test = np.asarray(test_data)\n",
    "Y = np.asarray(training_data)[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.25%\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=10, gamma=20)\n",
    "clf.fit(X, Y.ravel())\n",
    "prediction_classes = clf.predict(X_Test)\n",
    "numpy_predicted_classes = np.array(prediction_classes)\n",
    "numpy_true_test_data = np.array(test_data_true)\n",
    "\n",
    "accuracy = sum(numpy_true_test_data == numpy_predicted_classes) / K\n",
    "        \n",
    "print('Accuracy = ' + str(round(accuracy,4) * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2bd8c26a442d44da6f77d71c63a5d5ec634807a3105e8450172857d10d915d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
